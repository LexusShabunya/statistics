---
title: "ЛР2_Вар26_ШабуняАлексей_БСТ214"
author: "Шабуня Алексей Андреевич"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Подключаем необходимый для импорта данных пакет командой `library`, присваиваем импортированным данным имя `dataframe`:

```{r}
library('rio')
dataframe <- import('Данные по вариантам для выполнения типового расчета.xlsx')
```

Сохраним теперь отдельным объектом данные по исследуемому показателю, которые сохранены в файле в столбце `v26`:

```{r}
data <- dataframe['v26']
```

К нашим 100 наблюдениям добавилось одно лишнее, которое было внизу столбца, и тип данных не числовой (`numeric`), а текстовый (`character`). Исправить все можно так:

```{r}
data <- data[1:100,]
data <- as.data.frame(as.numeric(data))
```

### 2.1. Тесты на однородность дисперсий независимых выборок

Для того, чтобы выполнить проверку гипотез о параметрах нормального распределения по данным типового расчета, создадим две переменные: приняв за x первые 50 наблюдений нашей выборки, за y -- остальные 50 наблюдений:

```{r}
x <- data[1:50,] 
y <- data[51:100,] 
```

Проверка теста на равенство двух дисперсий $H_o:\sigma_1^2 = \sigma_2^2$ требует предварительной проверки двух выборок на нормальное распределение (см. п. 2.4). Тест очень чувствителен к отклонениям от нормальности, поэтому в случае отклонений следует воспользоваться другими тестами.

Сейчас же предположим, что мы имеем две выборки x и y, извлеченные из двух нормально распределенных независимых генеральных совокупностей $X \in N(\mu_x; \sigma_x); Y \in N(\mu_y; \sigma_y)$. В данном случае выборки взяты из типового расчета и поделены на 2 части.

Пусть $\alpha = 0.05$:

```{r}
alpha <- 0.05
```

Для проведения теста на равенство двух дисперсий при оговоренных допущениях используется F-статистика Фишера. По умолчанию данный тест проводится для двусторонней критической области. Поскольку для теста Фишера используется правосторонняя критическая область, это необходимо указать в качестве аргумента функции как `alternative = "greater"`:

```{r}
var.test(x, y, alternative = "greater") 
```

Результаты теста включают:

F-наблюдаемое: 1.9711,

p-value: 0.009617,

то есть все, что необходимо для проверки нулевой гипотезы. Так как `p-value` = 0.009617 меньше, чем 0,05, то $H_0$ отвергается. Значит, с вероятностью ошибки $\alpha = 0,05$ можно считать, что гипотеза о равенстве дисперсий генеральных совокупностей не верна.

Чтобы вывести F-критическое, можно воспользоваться встроенной функцией F-распределения, в данном случае нахождения его квантилей.

В нашем случае при использовании правосторонней критической области данного критерия нужна вероятность правого хвоста распределения, т.е. $P[X ≥ x]$, поэтому задаем это в функции, также указываем вероятность(в нашем случае $\alpha = 0,05$), а также степени свободы двух выборок(так как n в обоих случах равно 50, а степень свободы находится по формуле $\nu = n - 1$, то для обоих выборок $\nu = 49$:

```{r}
qf(alpha, 49, 49, lower.tail = FALSE)
```

Как видим, F-наблюдаемое \> F-критическое: 1.9711 \> 1.607289, следовательно, с вероятностью ошибки $\alpha = 0,05$ гипотеза о равенстве дисперсий генеральных совокупностей отвергается.

### 2.2. Тесты на равенство средних

#### 2.2.1. Сравнение среднего совокупности с заданным значением - параметрический тест (t-тест Стьюдента)

Проверка гипотезы о значении генеральной средней $H_o: \mu = \mu_0$ при неизвестной генеральной дисперсии $\sigma^2$ требует предварительной проверки выборки на нормальное распределение (см. п. 2.4).

Провести этот тест в R можно с помощью стандартной встроенной функции `t.test()`, которая поддерживает проверку гипотезы о равенстве среднего константе. Данная функция имеет аргумент `mu`, который отвечает за параметр проверяемого среднего значения гипотезы $H_o: \mu = \mu_0$.

Найдем среднее введенной нами ранее выборки x. Предположим, что выборка x извлечена из нормально распределенной генеральной совокупности $X \in N(\mu_x;\sigma_x)$.

Проверим состав нашей переменной с помощью функции проверки целостности данных `glimpse` из пакета `dplyr`:

```{r}
library(dplyr)
glimpse(x)
mean(x)
```

Получаем результат, показывающий нам, что переменная числовая, состоящая из 50 значений, ее среднее по выборке равно 2.3356.

Допустим, по нормативу среднее значение x должно составлять 2.3. Таким образом, нам по имеющейся в нашем распоряжении выборке необходимо проверить нулевую гипотезу: $H_0: \mu = 2.3$.

Проведем тест на проверку равенства средней нормативу:

```{r}
t.test(x, mu = 2.3)
```

В итоге получаем, что p-value = 0.7314 > 0.05 = $\alpha$. Следовательно, гипотеза $H_0: \mu = 2.3$ не отвергается на уровне значимости $\alpha = 0.05$ (средняя соответствует нормативу).

Наблюдаемое значение статистики критерия: t = 0.34521.

Доверительный интервал для генеральной средней по умолчанию строится в рамках теста с надежностью 0,95. Видим, что здесь он содержит значение норматива 2.3:

$$P(2.128359 < \mu < 2.542841) = 0.95$$

Чтобы вывести t-критическое, воспользуемся встроенной функцией t-распределения Стьюдента, в данном случае нахождения его квантилей.

В нашем случае при использовании двусторонней критической области данного критерия нужна вероятность $P[|T|\ge t]$, поэтому задаем в функции вероятность $\alpha/2$ (по умолчанию она выдает квантиль уровня $\alpha$, левый хвост, т.е. вероятность $P[T < t]= \alpha$), а также указываем количество степеней свободы 49.

```{r}
qt(alpha/2, 49)
```

Итак, получаем $|t_{набл.}| = 0.34521 < t_{крит.}= 2.009575$. Значит гипотеза $H_0: \mu = 2.3$ не отвергается на уровне значимости $\alpha = 0.05$ (средняя соответствует нормативу).

#### 2.2.3. Сравнение средних двух независимых нормально распределенных совокупностей - параметрический тест (t-тест Стьюдента)

После проведения теста на равенство дисперсий (п. 2.1), можно провести тест на равенство средних в двух (независимых) выборках, извлеченных из нормальных совокупностей. В нем используется t-статистика Стьюдента.

Выполнить этот тест можно с помощью уже знакомой нам по п. 2.2.1 функции `t.test()`. На входе функция получает две выборки x, y и два параметра: `var.equal` и `paired`. Первый из них отвечает за равенство дисперсий: `var.equal = TRUE` означает, что был проведён предыдущий тест (п. 2.1) и генеральные дисперсии неизвестны, но равны, вследствие чего будет использоваться t-тест Стьюдента. Параметр `paired = FALSE` означает, что выборки независимы. В качестве результата функция `t.test()` также возвращает t-наблюдаемое, степени свободы df и p-value и, кроме того, оценки средних выборок:

```{r}
t.test(x, y, var.equal = TRUE, paired = FALSE)
```

Мы наблюдаем, что p-value = 0.3012 > 0.05 = $\alpha$. Отсюда следует, что гипотеза $H_o: \mu_x = \mu_y$ не отвергается на уровне значимости $\alpha = 0.05$ (средние двух совокупностей с большой долей вероятности равны). На это также указывает и 95%-ный доверительный интервал их разности $(\mu_x−\mu_y)$, который содержит 0.

Наблюдаемое значение статистики критерия: $t_{набл.} = 1.0394$

Выведем t-критическое, для этого можно использовать функцию квантилей распределения Стьюдента: qt(0.975, 98). Будет выведено:

```{r}
qt(0.975, 98)
```

Получаем, что $|t_{набл.}| = 1.0394 < 1.984467 = t_{крит.}$. Значит гипотеза $H_o: \mu_x = \mu_y$ не отвергается на уровне значимости $\alpha = 0.05$ (средние двух совокупностей с большой долей вероятности равны).

Визуализировать различия (сходства) между средними можно, например, с помощью ящичковых диаграмм (boxplots).

Для построения этого графика организуем данные в виде таблицы:

```{r}
# Создаем таблицу данных из двух столбцов 
my_data <- data.frame(
                    group = rep(c("x", "y"), each = 50),
                    something = c(x, y)
                      )

print(my_data)
```

Теперь можем построить для наших двух переменных x и y ящичковые диаграммы. Для этого понадобится пакет `ggpubr`. И подгрузим его для работы в библиотеку, вызвав из него затем нужную нам функцию построения ящичковой диаграммы `ggboxplot`:

```{r, fig.cap= 'Рис. 4. Ящичковые диаграммы (boxplots) для переменных x и y, построенные с помощью функции ggboxplot пакета ggpubr'}
library("ggpubr") 
ggboxplot(my_data, x = "group", y = "something", 
          color = "group", 
          palette = c("blue", "red"), 
          ylab = "something", xlab = "Group")
```

Данный график показывает разброс каждой переменной, а также можно сделать вывод, что выборочные средние имеют совсем небольшую разницу.

### 2.3. Критерии проверки параметров биномиальных распределений

#### Условие из ДКР2 задачи 6 варианта 26 (5.131)

##### При анализе симметричности игрального шестигранного кубика выяснилось, что при 240 подбрасываниях «пятёрка» выпала 47 раз. В предположении, генеральная совокупность подчиняется биномиальному закону распределения, проверить на уровне значимости 0,05 следующие гипотезы:

#### 2.3.1. Тест на равенство вероятности успеха в испытании Бернулли определенной константе

##### Можно ли считать, что кубик симметричен? Или вероятность выпадения «пятерки» больше ожидаемой? (проверить против двух соответствующих конкурирующих гипотез).

Проверка гипотезы о значении неизвестной генеральной доли (вероятности) биномиально распределенной генеральной совокупности $B(n;p)$ $H_0:p=p_0$:

при достаточно больших объемах выборки (по крайней мере, n\>30 для адекватного применения ЦПТ и нормальной аппроксимации) осуществляется с помощью стандартной встроенной функции с воможностью поправки на непрерывность Йетса (Yates) (идет по умолчанию):

В нашем случае n = 240 (большая выборка); m = 47; $\alpha = 0.05$;

$H_0:p=0.2$

Первая конкурирующая гипотеза:

$$H_1: p_1 \neq 0.2$$

```{r}
prop.test(47, 240, p = 0.2)
```

Здесь мы наблюдаем, что p-value = 0.9357 \> 0.05 = $\alpha$ -- следовательно, гипотеза $H_0:p=0.2$ не отвергается на уровне значимости $\alpha = 0.05$.

Надо отметить, что результаты без поправки Йетса не сильно отличаются:

```{r}
prop.test(47, 240, p = 0.2, correct = FALSE)
```

И конечно, в этом случае применима и первая функция с точным биномиальным тестом:

```{r}
binom.test(47, 240, p = 0.2)
```

Здесь все три теста дали близкие результаты p-value - все больше уровня значимости $\alpha = 0.05$ -- следовательно, гипотеза $H_0:p=0.2$ не отвергается на уровне значимости $\alpha = 0.05$.

При второй конкурирующей гипотезе:

$$H_1: p_1 > 0.2$$

```{r}
prop.test(47, 240, p = 0.2, alternative = 'greater')
```

Здесь мы наблюдаем, что p-value = 0.5322 \> 0.05 = $\alpha$ -- следовательно, гипотеза $H_0:p=0.2$ не отвергается на уровне значимости $0.05$.

Надо отметить, что результаты без поправки Йетса не сильно отличаются:

```{r}
prop.test(47, 240, p = 0.2, alternative = 'greater', correct = FALSE)
```

И конечно, в этом случае применима и первая функция с точным биномиальным тестом:

```{r}
binom.test(47, 240, p = 0.2, alternative = 'greater')
```

Здесь все три теста дали близкие результаты p-value - все больше уровня значимости $\alpha = 0.05$ -- следовательно, гипотеза $H_0:p=0.2$ не отвергается на уровне значимости $\alpha$.

#### 2.3.2. Тест на равенство вероятностей успеха в испытаниях Бернулли для нескольких биномиально распределенных совокупностей

##### б) Сравнить симметричность данного кубика с другим, у которого при 360 подбрасываниях «пятёрка»
выпала 72 раза.

Проверка гипотезы о равенстве вероятностей (генеральных долей) биномиально распределенных генеральных совокупностей $B(n_i;p_i)$ $H_0: p_1 = p_2 = ... = p_k$ осуществляется с помощью `prop.test()`, где m и n задаются в виде векторов успехов и числа испытаний.

В данной задаче:

$$H_0: p_1 = p_2$$

$$H_1: p_1 \neq p_2$$

Из условия: $n_1 = 240, n_2 = 360, m_1 = 47, m_2 = 72$.

```{r}
prop.test(x = c(47, 72), n = c(240, 360),correct = FALSE)

qchisq(0.95,1)
```

$\chi_{набл.}^2 = 0.015724 < 3.841459 = \chi_{крит.}^2$, $p-value = 0.9002 > 0.05 = \alpha$, следовательно, нулевая гипотеза об однородности вероятностей не отвергается на уровне значимости 0.05.

### 2.4. Критерии согласия эмпирического распределения с теоретическим

```{r}
volume <- data[[1]] 
```

Рассмотрим несколько критериев проверки согласия выборки с теоретическим распределением и проверим данные типового расчета.

#### 2.4.2. Критерий Андерсона-Дарлинга

Для нахождения нескольких критериев нам понадобится пакет `nortest`, поэтому установим его, и проведем первый тест - Андерсона-Дарлинга при помощи функции `ad.test()`:

```{r}
library('nortest')
ad.test(volume)
```

Здесь мы видим, что p-value = 1.37e-06 \< 0.05 = $\alpha$, следовательно гипотеза о нормальном распределении отвергается.

#### 2.4.3. Критерий Лиллиефорса

Данный критерий - модификация теста Колмогорова- Смирнова, его можно проверить при помощи функции `lillie.test()` из установленного нами пакета `nortest`. Проверим нашу выборку из типового расчета на нормальность:

```{r}
lillie.test(volume)
```

В итоге получаем, что p-value = 1.155e-06 \< 0.05 = $\alpha$, поэтому гипотеза о нормальности распределения отвергается с вероятностью ошибки $\alpha = 0.05$.

#### 2.4.4. Критерий Пирсона

Это один из первых и наиболее распространенных критериев согласия, как показывают результаты научных исследований, показывает достаточно неплохие результаты по сравнению с другими критериями, при этом очень прост и понятен в реализации.

Сейчас нам понадобится пакет `fBasics` и функция `pchiTest()`:

```{r}
library('fBasics')

pchiTest(volume)
```

Для критерия Пирсона мы получаем значение p-value, которое меньше 0.05, следовательно можно сделать вывод о том, что гипотеза о нормальности распределения отвергается с вероятностью ошибки $\alpha = 0.05$.

#### 2.4.5. Критерий Жарка-Бера

Этот тест используется для проверки нормальности распределения величины. Разработаны две модификации теста, которые позволяют проверить классическим (`robust = FALSE`) или Робастным методом (`robust = TRUE`). Проверим на наших данных, предварительно установив пакет `DescTools` и применив функцию `JarqueBeraTest`:

```{r}
library('DescTools')

JarqueBeraTest(volume, robust = FALSE)

JarqueBeraTest(volume, robust = TRUE)
```
Видно, что в разных случаях p-value разное, в классическом методе р-value \< 0.05, а в Робастном методе р-value \> 0.05, поэтому однозначного ответа дать нельзя, всё зависит от используемой модификации. В случае с классическим методом - гипотеза о нормальности распределения отвергается с вероятностью ошибки $\alpha = 0.05$, то есть недостаточно оснований полагать что генеральная совокупность подчиняется нормальному закону распределения. А в случае с Робастным методом - гипотеза о нормальности распределения не отвергается, следовательно на уровне значимости $\alpha = 0.05$ можно считать что генеральная совокупность подчиняется нормальному закону распределения.

#### 2.4.6. Д'Агустино тест

Проведем еще один тест на критерий согласия, при помощи функции `dagoTest` из пакета `fBasics`:

```{r}
dagoTest(volume)
```

По итогу получаем все p-value значения меньше 0.05, следовательно гипотеза о нормальности отвергается с вероятностью ошибки $\alpha = 0.05$.

Сущее большинство критериев отвергают нулевую гипотезу, поэтому нет оснований считать, что генеральная совокупность подчиняется нормальному закону распределения.
